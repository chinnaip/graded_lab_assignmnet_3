{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title"
   },
   "source": [
    "# Assignment: Deep Neural Network for Handwritten Digit Recognition\n",
    "\n",
    "**Objective:** Implement a multi-layer Deep Neural Network (DNN) to classify handwritten digits from the MNIST dataset with at least **97% accuracy** on the test set.\n",
    "\n",
    "## Dataset Overview\n",
    "The MNIST dataset consists of 70,000 grayscale images of handwritten digits (0–9).\n",
    "- **Image size:** 28 × 28 pixels\n",
    "- **Training set:** 60,000 images\n",
    "- **Testing set:** 10,000 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imports"
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "task1_header"
   },
   "source": [
    "## Task 1: Data Preprocessing\n",
    "\n",
    "Before feeding data into a DNN, it must be formatted correctly:\n",
    "- **Normalization:** Convert pixel values from [0, 255] to [0, 1]\n",
    "- **Flattening:** Reshape the 28×28 2D images into a 1D vector of size 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "data_preprocessing"
   },
   "outputs": [],
   "source": [
    "# Load the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "print(\"Raw data shapes:\")\n",
    "print(f\"  x_train: {x_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"  x_test:  {x_test.shape},  y_test:  {y_test.shape}\")\n",
    "print(f\"  Pixel value range before normalization: [{x_train.min()}, {x_train.max()}]\")\n",
    "\n",
    "# --- Normalization: scale pixel values from [0, 255] to [0, 1] ---\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test  = x_test.astype('float32')  / 255.0\n",
    "\n",
    "# --- Flattening: reshape 28x28 images to 1D vectors of size 784 ---\n",
    "x_train_flat = x_train.reshape(-1, 784)\n",
    "x_test_flat  = x_test.reshape(-1, 784)\n",
    "\n",
    "print(\"\\nAfter preprocessing:\")\n",
    "print(f\"  x_train_flat: {x_train_flat.shape}\")\n",
    "print(f\"  x_test_flat:  {x_test_flat.shape}\")\n",
    "print(f\"  Pixel value range after normalization: [{x_train_flat.min():.1f}, {x_train_flat.max():.1f}]\")\n",
    "\n",
    "# One-hot encode labels (required for categorical_crossentropy)\n",
    "y_train_cat = to_categorical(y_train, num_classes=10)\n",
    "y_test_cat  = to_categorical(y_test,  num_classes=10)\n",
    "print(f\"\\n  y_train_cat shape: {y_train_cat.shape}  (one-hot encoded)\")\n",
    "\n",
    "# Visualize a few sample images\n",
    "fig, axes = plt.subplots(2, 5, figsize=(10, 4))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(x_train[i], cmap='gray')\n",
    "    ax.set_title(f\"Label: {y_train[i]}\")\n",
    "    ax.axis('off')\n",
    "plt.suptitle(\"Sample MNIST Images\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "task2_header"
   },
   "source": [
    "## Task 2: Architecture Design\n",
    "\n",
    "Build a Sequential model with the following layers:\n",
    "| Layer | Details |\n",
    "|-------|---------|\n",
    "| Input | 784 units |\n",
    "| Hidden Layer 1 | 512 neurons, ReLU activation |\n",
    "| Dropout | 20% rate (prevents overfitting) |\n",
    "| Hidden Layer 2 | 256 neurons, ReLU activation |\n",
    "| Output Layer | 10 neurons, Softmax activation |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "model_architecture"
   },
   "outputs": [],
   "source": [
    "# Build the DNN model\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        # Input layer (784 units — one per flattened pixel)\n",
    "        layers.Input(shape=(784,)),\n",
    "\n",
    "        # Hidden Layer 1: 512 neurons with ReLU activation\n",
    "        layers.Dense(512, activation='relu'),\n",
    "\n",
    "        # Dropout Layer: 20% rate to reduce overfitting\n",
    "        layers.Dropout(0.2),\n",
    "\n",
    "        # Hidden Layer 2: 256 neurons with ReLU activation\n",
    "        layers.Dense(256, activation='relu'),\n",
    "\n",
    "        # Output Layer: 10 neurons with Softmax (one probability per digit class)\n",
    "        layers.Dense(10, activation='softmax'),\n",
    "    ],\n",
    "    name=\"DNN_MNIST\",\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "task3_header"
   },
   "source": [
    "## Task 3: Training Configuration\n",
    "\n",
    "Hyperparameters:\n",
    "- **Loss Function:** `categorical_crossentropy`\n",
    "- **Optimizer:** Adam\n",
    "- **Metrics:** accuracy\n",
    "- **Batch Size:** 128\n",
    "- **Epochs:** 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "compile_and_train"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    x_train_flat, y_train_cat,\n",
    "    batch_size=128,\n",
    "    epochs=15,\n",
    "    validation_split=0.1,   # 10% of training data used for validation\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evaluate_model"
   },
   "outputs": [],
   "source": [
    "# Evaluate on the test set\n",
    "test_loss, test_accuracy = model.evaluate(x_test_flat, y_test_cat, verbose=0)\n",
    "print(f\"Test Loss:     {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "if test_accuracy >= 0.97:\n",
    "    print(\"\\n✅ Target of ≥97% accuracy achieved!\")\n",
    "else:\n",
    "    print(\"\\n⚠️  Target accuracy not yet reached. Consider more epochs or tuning.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "analysis_header"
   },
   "source": [
    "## Analysis Questions\n",
    "\n",
    "### Q1 – Overfitting Check\n",
    "Plot training accuracy vs. validation accuracy. Does the model overfit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "overfitting_plot"
   },
   "outputs": [],
   "source": [
    "epochs_range = range(1, len(history.history['accuracy']) + 1)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Accuracy\n",
    "axes[0].plot(epochs_range, history.history['accuracy'],     label='Training Accuracy',   marker='o')\n",
    "axes[0].plot(epochs_range, history.history['val_accuracy'], label='Validation Accuracy', marker='s')\n",
    "axes[0].set_title('Training vs Validation Accuracy')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Loss\n",
    "axes[1].plot(epochs_range, history.history['loss'],     label='Training Loss',   marker='o')\n",
    "axes[1].plot(epochs_range, history.history['val_loss'], label='Validation Loss', marker='s')\n",
    "axes[1].set_title('Training vs Validation Loss')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Overfitting analysis\n",
    "final_train_acc = history.history['accuracy'][-1]\n",
    "final_val_acc   = history.history['val_accuracy'][-1]\n",
    "gap = final_train_acc - final_val_acc\n",
    "\n",
    "print(f\"Final Training Accuracy:   {final_train_acc * 100:.2f}%\")\n",
    "print(f\"Final Validation Accuracy: {final_val_acc * 100:.2f}%\")\n",
    "print(f\"Accuracy Gap (train - val): {gap * 100:.2f}%\")\n",
    "print()\n",
    "if gap < 0.02:\n",
    "    print(\"✅ The model does NOT overfit significantly. The training and validation accuracy \"\n",
    "          \"curves closely follow each other, and the Dropout layer is effectively regularising \"\n",
    "          \"the network.\")\n",
    "else:\n",
    "    print(\"⚠️  A noticeable gap exists between training and validation accuracy, indicating \"\n",
    "          \"some degree of overfitting. Increasing the Dropout rate or adding L2 regularisation \"\n",
    "          \"could help.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q2_header"
   },
   "source": [
    "### Q2 – Activation Functions: ReLU vs Sigmoid\n",
    "\n",
    "What happens to convergence speed if ReLU is replaced by Sigmoid in the hidden layers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sigmoid_comparison"
   },
   "outputs": [],
   "source": [
    "# Build an identical model but using Sigmoid in the hidden layers\n",
    "model_sigmoid = keras.Sequential(\n",
    "    [\n",
    "        layers.Input(shape=(784,)),\n",
    "        layers.Dense(512, activation='sigmoid'),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(256, activation='sigmoid'),\n",
    "        layers.Dense(10, activation='softmax'),\n",
    "    ],\n",
    "    name=\"DNN_MNIST_Sigmoid\",\n",
    ")\n",
    "\n",
    "model_sigmoid.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "history_sigmoid = model_sigmoid.fit(\n",
    "    x_train_flat, y_train_cat,\n",
    "    batch_size=128,\n",
    "    epochs=15,\n",
    "    validation_split=0.1,\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "# Compare accuracy curves\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs_range, history.history['val_accuracy'],         label='ReLU – Validation Accuracy',   linewidth=2)\n",
    "plt.plot(epochs_range, history_sigmoid.history['val_accuracy'], label='Sigmoid – Validation Accuracy', linewidth=2, linestyle='--')\n",
    "plt.title('Validation Accuracy: ReLU vs Sigmoid')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(\"ReLU   final val accuracy:\", f\"{history.history['val_accuracy'][-1]*100:.2f}%\")\n",
    "print(\"Sigmoid final val accuracy:\", f\"{history_sigmoid.history['val_accuracy'][-1]*100:.2f}%\")\n",
    "print()\n",
    "print(\"\"\"\n",
    "Analysis:\n",
    "---------\n",
    "ReLU converges faster than Sigmoid because:\n",
    "  1. ReLU avoids the vanishing gradient problem: its gradient is either 0 or 1,\n",
    "     so gradients propagate efficiently through many layers.\n",
    "  2. Sigmoid saturates at both extremes (output → 0 or 1), causing very small\n",
    "     gradients and slow weight updates — especially in deeper networks.\n",
    "  3. ReLU is also computationally cheaper (a simple max(0, x) operation).\n",
    "As a result, the ReLU model typically reaches higher accuracy earlier in training.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q3_header"
   },
   "source": [
    "### Q3 – Error Analysis\n",
    "\n",
    "Identify three images the model classified incorrectly and explain why it may have struggled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "error_analysis"
   },
   "outputs": [],
   "source": [
    "# Get model predictions on the test set\n",
    "y_pred_probs = model.predict(x_test_flat, verbose=0)\n",
    "y_pred       = np.argmax(y_pred_probs, axis=1)\n",
    "y_true       = y_test  # original integer labels\n",
    "\n",
    "# Find misclassified samples\n",
    "misclassified_idx = np.where(y_pred != y_true)[0]\n",
    "print(f\"Total misclassified images: {len(misclassified_idx)} / {len(y_true)}\")\n",
    "\n",
    "# Display the first 3 misclassified images\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "for i, ax in enumerate(axes):\n",
    "    idx = misclassified_idx[i]\n",
    "    ax.imshow(x_test[idx], cmap='gray')\n",
    "    ax.set_title(\n",
    "        f\"True: {y_true[idx]}  Predicted: {y_pred[idx]}\\n\"\n",
    "        f\"Confidence: {y_pred_probs[idx, y_pred[idx]]*100:.1f}%\",\n",
    "        fontsize=11,\n",
    "    )\n",
    "    ax.axis('off')\n",
    "plt.suptitle(\"Misclassified Test Images\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\"\"\n",
    "Why might the model struggle with these images?\n",
    "------------------------------------------------\n",
    "Common reasons for misclassification in MNIST:\n",
    "  1. Ambiguous handwriting: Digits like 4 vs 9, 3 vs 8, or 1 vs 7 share\n",
    "     similar stroke patterns and are visually close.\n",
    "  2. Unusual writing styles: Some writers form digits in non-standard ways\n",
    "     (e.g., a '2' with an extra loop resembling a '3').\n",
    "  3. Image noise or skew: A digit written at an angle or with heavy pen\n",
    "     pressure can look atypical to the model.\n",
    "Because this is a flat DNN (no convolutions), it lacks spatial awareness\n",
    "and is more sensitive to positional variations compared with a CNN.\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
